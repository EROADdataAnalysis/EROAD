{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 7 - Classification, Naive Bayes, Generalization, Overfitting, Evaluation, Cross-validation and Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Lecture 7- Classification, Naive Bayes, Generalization, Overfitting, Evaluation, Cross-validation and Scikit-learn](#Lecture-6--Classification,-Naive-Bayes,-Generalization,-Overfitting,-Evaluation,-Cross-validation-and-Scikit-learn)\n",
    "\t* &nbsp;\n",
    "\t\t* [Content](#Content)\n",
    "\t\t* [Learning Outcomes](#Learning-Outcomes)\n",
    "* [Classification](#Classification)\n",
    "\t* &nbsp;\n",
    "\t\t* [Example dataset - Wine](#Example-dataset---Wine)\n",
    "* [Naive Bayes](#Naive-Bayes)\n",
    "\t* &nbsp;\n",
    "\t\t* &nbsp;\n",
    "\t\t\t* [Probabilities](#Probabilities)\n",
    "\t\t\t* [Joint probabilities](#Joint-probabilities)\n",
    "\t\t* [Probability density functions](#Probability-density-functions)\n",
    "\t\t* [Steps for calculating the classification for naive Bayes](#Steps-for-calculating-the-classification-for-naive-Bayes)\n",
    "\t\t* [Comparing Naive Bayes to k-NN](#Comparing-Naive-Bayes-to-k-NN)\n",
    "* [Generalization](#Generalization)\n",
    "* [Overfitting](#Overfitting)\n",
    "* [Classifier Evaluation](#Classifier-Evaluation)\n",
    "* [Cross-Validation](#Cross-Validation)\n",
    "* [Machine Learning - Evaluating Multiple Algorithms](#Machine-Learning---Evaluating-Multiple-Algorithms)\n",
    "* [No Free Lunch](#No-Free-Lunch)\n",
    "* [Classification Process Summarized](#Classification-Process-Summarized)\n",
    "* [Putting it all together in scikit-learn](#Putting-it-all-together-in-scikit-learn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Classification\n",
    "2. Naive Bayes\n",
    "3. Generalization\n",
    "4. Overfitting\n",
    "5. Classifiers goodness-of-fit\n",
    "6. Cross-validation\n",
    "7. Comparing multiple classifiers\n",
    "8. Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of this lecture, you should be able to:\n",
    "\n",
    "* explain the difference between classification and regression\n",
    "* program and apply the Naive Bayes to classification tasks\n",
    "* explain the theory of generalization, the phenomenon of overfitting, and the 'no free lunch' theorem\n",
    "* discuss and apply various measures for evaluating classifier accuracy\n",
    "* use cross-validation for training and evaluating classifiers\n",
    "* compare the accuracies of multiple classification algorithms across multiple datasets\n",
    "* use the scikit-learn module to train and test Naive Bayes classifiers\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, classification is the task of devising a *classifier* capable of assigning a particular class/category to an unknown instance/sample from a set of possible classes. A machine learning algorithm builds, evaluates and optimises a classifier on the training data in  such a way that it discriminate instances of different classes from each other, in the hope that these patterns will *generalise* and be valid on data which the algorithm has not *seen* during the training phase. \n",
    "\n",
    "Classification (like regression) belong to a family of **supervised learning** methods. In order to be able to perform supervised learning, a training set is required where all of the samples' **class values are known in advance**. The classifier is **trained** to learn how to map each of the samples' features/attributes to their corresponding class labels.\n",
    "\n",
    "Once the classifier is trained to do this on a fully labelled dataset, the classifier is then used to classify unknown samples into class labels given the samples feature vectors only. If there are two classes used in the prediction, then this is referred to as a **binary classification problem**. If there are more than just two classes in the dataset, this is than called a **multiclass classification problem**. \n",
    "\n",
    "As the number of classes in a prediction problem increase, so does the difficulty in maintaining high accuracy. \n",
    "\n",
    "A classifier can be fixed-size (irrespective of the amount of data provided for training), or it can be variable, and thus grow in complexity with the amount of available data, allowing it to capture and encode complex decision boundaries.\n",
    "\n",
    "Classification is an immensely vital and widely used technique. Examples of classification are found in classifying whether or not a given email is of a class \"spam\" or \"non-spam\"; banks use it to classify if a given transaction is \"legitimate\" or \"fraudulent\" class; medical staff have technologies to assigning a diagnosis to a given patient as described by observed characteristics of the patient; financial analysts use it to predict if a given stock should be classified as \"invest now\" or \"do not invest\" at a given point in time given a range of accompanying indicators. \n",
    "\n",
    "In order to perform classification, an algorithm is first needed that creates a classifier. There are many types of machine learning classification algorithms. \n",
    "\n",
    "We have looked kNN and seen how it can be used as a classification algorithm. Some of the other well known ones are Neural Networks, Support Vector Machines, Tree classifiers, Boosted Ensembles, Bagging, Random Forests as well as Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example dataset - Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will return to the Wine dataset to explore classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Flavanoids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Magnesium  Flavanoids\n",
       "0      1       2.80        3.06\n",
       "1      1       2.65        2.76\n",
       "2      1       2.80        3.24\n",
       "3      1       3.85        3.49\n",
       "4      1       2.80        2.69"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mtpl\n",
    "#import mpld3\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.io.parsers.read_csv(\n",
    "    'wine_data.csv',\n",
    "     usecols=[0,6,7]\n",
    "    )\n",
    "\n",
    "df.columns=['Class','Magnesium','Flavanoids']\n",
    "\n",
    "df['Class'].replace('3', 0, inplace=True)\n",
    "df.to_csv('wine_data_test.csv', header=None, index=None)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm we have 3 class labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class           int64\n",
       "Magnesium     float64\n",
       "Flavanoids    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In classification problems, the **ability to separate classes** from one another is the most important consideration. Histograms of the feature values per class type, can be a useful tool for **eyeballing** some features and to get a rough feeling for their **discriminative power**. \n",
    "\n",
    "Here we are visualising the histograms of the two features for each of the three classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAH8CAYAAABl8FOBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x84767f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "colors = ('blue', 'red', 'green')\n",
    "\n",
    "for label,color in zip(range(0,3), colors):\n",
    "    mean = np.mean(df['Magnesium'][df['Class'] == label]) # class sample mean\n",
    "    stdev = np.std(df['Magnesium'][df['Class'] == label]) # class standard deviation\n",
    "    df['Magnesium'][df['Class'] == label].hist(alpha=0.3, # opacity level\n",
    "             label='class {} ($\\mu={:.2f}$, $\\sigma={:.2f}$)'.format(label, mean, stdev), \n",
    "             color=color,\n",
    "             bins=15)\n",
    "\n",
    "plt.title('Wine data set - Distribution of Magnesium content')\n",
    "plt.xlabel('Magnesium content', fontsize=14)\n",
    "plt.ylabel('count', fontsize=14)\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAH8CAYAAAB/zLMPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkqTKTMgkSZIqMyGTJEmqzIRMkiSpsv8H/Em5wv9adpMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8476940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "colors = ('blue', 'red', 'green')\n",
    "\n",
    "for label,color in zip(range(0,3), colors):\n",
    "    mean = np.mean(df['Flavanoids'][df['Class'] == label]) # class sample mean\n",
    "    stdev = np.std(df['Flavanoids'][df['Class'] == label]) # class standard deviation\n",
    "    df['Flavanoids'][df['Class'] == label].hist(alpha=0.3, # opacity level\n",
    "             label='class {} ($\\mu={:.2f}$, $\\sigma={:.2f}$)'.format(label, mean, stdev), \n",
    "             color=color,\n",
    "             bins=15)\n",
    "\n",
    "plt.title('Wine data set - Distribution of Flavanoids content')\n",
    "plt.xlabel('Flavanoids content', fontsize=14)\n",
    "plt.ylabel('count', fontsize=14)\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes (NB) is a classical statistical machine learning algorithm. It is based on one of the most important equations both in statistics as well as in science as whole - the **Bayes Theorem**. \n",
    "\n",
    "The Bayes Theorem is the foundation of a large branch of statistics that has an increasing relevance in solving real-world data science problems called **Bayesian Statistics**. Under this subfield of statistics, advanced methods like, Bayesian networks, Hidden Markov Models, Markov Random fields and probabilistic relational models are situated.\n",
    "\n",
    "With the Bayes Theorem the **evidence about the true state of the world is expressed in terms of degrees of belief (probabilities)**. As such, the Bayes Theorem deals with **conditional probabilities between different events**. \n",
    "\n",
    "*It allows us to calculate the probability of some even A occurring given that some evidence B is true.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we are developing an email spam filter. We are dealing with two classes, **spam** and **non-spam**. We look through all the spam emails in our email account and we find that 20% of them have the word 'Viagra' in them, while 80% contain the word 'Bank'. We would express this as: \n",
    "\n",
    "\\begin{equation}\n",
    "p(Viagra) = 0.2\n",
    "\\end{equation}\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{equation}\n",
    "p(Bank) = 0.8\n",
    "\\end{equation}\n",
    "\n",
    "If we assume that the occurrence of the above words in the emails is independent of each other (which means that one does not influence the other), than we can calculate the probability of encountering a spam email having both these words is:\n",
    "\n",
    "0.2 $\\times$ 0.8 = 0.16, which is p(Viagra)p(Bank).\n",
    "\n",
    "This can be fully expressed as:\n",
    "\n",
    "\\begin{equation}\n",
    "p(Viagra\\ and\\ Bank | Spam)\n",
    "\\end{equation}\n",
    "\n",
    "meaning the probability of Viagra and Bank occurring together, given a spam email.\n",
    "\n",
    "The above in effect expresses:\n",
    "\n",
    "\\begin{equation}\n",
    "p(Words | Class)\n",
    "\\end{equation}\n",
    "\n",
    "meaning the probability of certain words occurring for a given class which could be spam or non-spam. However, we are interested in prediction, so for us the above needs to be inverted because we want to know what is the probability of something being spam or non-spam given certain words we have come across in an email. In effect, what we are interested in is:\n",
    "\n",
    "\\begin{equation}\n",
    "p(Class | Words)\n",
    "\\end{equation}\n",
    "\n",
    "Our problem is that \n",
    "\n",
    "\\begin{equation}\n",
    "p(Class | Words) \\neq p(Words | Class)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Fortunately, 250 years ago, the British mathematician **Thomas Bayes** figured out how to resolve this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joint probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since\n",
    "\n",
    "\\begin{equation}\n",
    "p(A\\ and\\ B) = p(B)p(A) \n",
    "\\end{equation}\n",
    "\n",
    "**is not always true**, generally the joint probability of two events is therefore expressed as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "p(A\\ and\\ B) = p(B|A)p(A)\n",
    "\\end{equation}\n",
    "\n",
    "where p(B|A) represents the probability of B occurring, given that A has occurred. The above equation is also  interchangeable as:\n",
    "\n",
    "\\begin{equation}\n",
    "p(A\\ and\\ B) = p(A|B)p(B)\n",
    "\\end{equation}\n",
    "\n",
    "by pulling the two pieces together we have: \n",
    "\n",
    "\\begin{equation}\n",
    "p(B|A)p(A) = p(A|B)p(B)\n",
    "\\end{equation}\n",
    "\n",
    "This now brings us to the Bayes Theorem and to the solution to our problem. For our problem, if we make B the class label of 'spam' (which is the probability we would like to predict), and A the words in the email (like viagra or bank), then we can solve by re-arranging this equation as:\n",
    "\n",
    "\\begin{equation}\n",
    "P(B|A) = \\frac{P(A | B)\\, P(B)}{P(A)}\\cdot\n",
    "\\end{equation}\n",
    "\n",
    "By plugging in our problem into the formula, we would get:\n",
    "\n",
    "\\begin{equation}\n",
    "P(Class|Words) = \\frac{P(Words | Class)\\, P(Class)}{P(Words)}\\cdot\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breaking the formula down, P(Words|Class) is called the **likelihood** and we can calculate this from our training set. The likelihood can be phrased as given all the spam emails, what is the probability that the words like 'viagra' and 'bank' occur in any document. It is essentially the product of each of the probabilities for every individual word.\n",
    "\n",
    "Naive Bayes is naive, because it assumes independence amongst the features in the calculation of the likelihood which in our example we express simply as p(Viagra)p(Bank).\n",
    "\n",
    "The P(Class) is called the **prior**. This we can also calculate from our dataset as being the proportion of emails that are classed as spam.\n",
    "\n",
    "The P(Words) is called the **normalising constant** (which is simply the probability of seeing this pattern without knowing what class it belongs to  - this is the least important component and in the end reduces down to simply the sum of all class probabilities), while the P(Class|Words) is called the **posterior** and is the result we are looking for.\n",
    "\n",
    "Let us continue the email spam filter example, but before we proceed we will need to complete the describing our dataset.\n",
    "\n",
    "Say we were examining a total of 100 emails, both spam and non-spam. 40 of those were spam and the rest were not. Of the 60 emails that were not spam, the word 'Viagra' appeared 5% and the word 'Bank' 10%. Across the entire dataset, the probability of finding 'Viagra' and 'Bank' in the emails, irrespective of what class the email belonged to was 7% (but this part can be left out).\n",
    "\n",
    "Our goal is to find out which class label is the most probable given the particular word features:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9142857142857144"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#caclulate p(spam| viagra and bank)\n",
    "((0.2 * 0.8) * 0.4) / (0.07)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04285714285714286"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#caclulate p(non-spam| viagra and bank)\n",
    "((0.05 * 0.1) * 0.6) / (0.07)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can say that the probability of an email containing words viagra and bank is more probable to be spam than non-spam and we therefore assign the class label to the feature ['Viagra','Bank'] as **spam**.\n",
    "\n",
    "In many classification tasks, you have to deal with incomplete or missing values. As it turns out **Naive Bayes is really good for dealing with missing values and is able to produce a classification without having all the features, whereby the likelihood is simply calculated by excluding the particular missing feature.**\n",
    "\n",
    "The above simplistic example considered features that were **categorical** and were represented as frequencies. \n",
    "\n",
    "How would we apply Naive Bayes to the wine dataset where the features for 'Magnesium' and 'Flavanoids' are numerical?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability density functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of the Gaussian (normal) probability density function (PDF)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xbd24518>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAH4CAYAAAD+YRGXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc037e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "h = np.random.randn(1000)\n",
    "h.sort()\n",
    "fit = stats.norm.pdf(h, np.mean(h), np.std(h))  #this is a fitting indeed\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(h,fit,'-')\n",
    "plt.title('Gaussion PDF')\n",
    "plt.xlabel('X with mean 0 and std 1')\n",
    "plt.ylabel('Probability')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PDF for the normal distribution is given by a rather formidable looking expression:\n",
    "<div style=\"font-size: 150%;\"> \n",
    "\\begin{equation}\n",
    "f(x, \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{ -\\frac{(x-\\mu)^2}{2\\sigma^2} }\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a deep breath and relax though. \n",
    "\n",
    "All we need to do is calculate the mean $\\mu$, standard deviation $\\sigma$ and plug them together with our value $x$ into the equation in order to get the probability that our quantity lies within a small region of $x$ for each of the class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps for calculating the classification for naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each class:\n",
    "\n",
    "1. Calculate the probability for each of the features and then calculate their product - this represents the likelihood component of the Bayes Theorem.\n",
    "\n",
    "2. Multiply the likelihood by the prior for a given class (the proportion of all samples belonging to this class that make up the training dataset) - to give us the posterior probability that we are finally looking for.\n",
    "\n",
    "3. The class with the largest posterior probability is the class that wins the classification.\n",
    "\n",
    "4. Divide the posterior of each class with the sum of all posteriors in order to normalize and to finish up with a more interpretable probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** write a function to calculate the PDF for a normal distribution as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pdf_gaussian(x, mean, std):\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = 66 \n",
    "mean = 73\n",
    "std = 6.2\n",
    "pdf_gaussian(x, mean, std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the wine dataset we saw previously: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    '../datasets/wine_data.csv',\n",
    "     usecols=[0,6,7]\n",
    "    )\n",
    "print df.columns\n",
    "df.columns=['Class','Magnesium','Flavanoids']\n",
    "df['Class'].replace(3, 0, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Write a function takes a data frame and a class label and returns a dictionary containing the keys for each of the feature names in the dataset with an associated list having 2 elements, where the first is the mean and the second the standard deviation of the given feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_class_statistics(df, class_label):\n",
    "    class_distr = {}\n",
    "    feature_types = []\n",
    "    \n",
    "    feature_types =  df.columns[1:]\n",
    "    means = (df[feature_types][df.Class == class_label]).mean()\n",
    "    stds = (df[feature_types][df.Class == class_label]).std()\n",
    "    \n",
    "    for feat in feature_types:\n",
    "        #YOUR CODE HERE\n",
    "        \n",
    "    return class_distr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calculate_class_statistics(df, 1)\n",
    "#SHOULD RETURN:\n",
    "#{'Flavanoids': [2.982372881355932, 0.39749360863676325],\n",
    "# 'Magnesium': [2.8401694915254234, 0.33896135231546792]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Write a function to train a NB classifier that takes in a data frame and returns a dictionary containing the following:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{'0': \n",
    "  {'Flavanoids': [0.78145833333333314, 0.29350406560186298],\n",
    "  'Magnesium': [1.6787500000000002, 0.35697085523801758],\n",
    "  'Prior': 0.2696629213483146},\n",
    " '1': \n",
    "  {'Flavanoids': [2.982372881355932, 0.3974936086367577],\n",
    "  'Magnesium': [2.8401694915254234, 0.33896135231546692],\n",
    "  'Prior': 0.33146067415730335},\n",
    " '2': \n",
    "  {'Flavanoids': [2.0808450704225359, 0.70570075908150276],\n",
    "  'Magnesium': [2.2588732394366198, 0.54536108430437336],\n",
    "  'Prior': 0.398876404494382}}\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the key is the class label and the value is a dictionary, containing means and standard deviations for each feature for each class, as well as a key for the prior and its associated value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_naive_bayes(df):\n",
    "    NB_classifier = {}\n",
    "    class_labels = df.Class.unique()\n",
    "    \n",
    "    for i in class_labels:\n",
    "        #YOUR CODE HERE\n",
    "        \n",
    "        \n",
    "    return NB_classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NB_classifer = train_naive_bayes(df)\n",
    "NB_classifer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** We are now going to move to classification. Write a function that takes as input a tuple from the dictionary above as well as a series object to classify and returns the Bayes probability for this class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_NB_probability_single_class(nb_classifier, series_x):\n",
    "    likelihood = 1.0 \n",
    "    \n",
    "    for feat in nb_classifier.keys():\n",
    "        #YOUR CODE HERE\n",
    "            \n",
    "\n",
    "    return posterior\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series_x = pd.Series([2.0, 2.3], index=['Flavanoids', 'Magnesium'])\n",
    "\n",
    "calculate_NB_probability_single_class(NB_classifer[str(1)], series_x)\n",
    "#SHOULD RETURN 0.0051879593513192053\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Write a function that classifies a series object into a class and returns its probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify_naive_bayes(NB_classifer, series_x):\n",
    "    classification = -1\n",
    "    classification_probabilities = []\n",
    "    prob = 0.0\n",
    "    total_ptobabilities = 0.0\n",
    "    \n",
    "    \n",
    "    for i in NB_classifer:\n",
    "        #YOUR CODE HERE\n",
    "    \n",
    "    #select winning class\n",
    "    for i in range(len(classification_probabilities)):\n",
    "        #YOUR CODE HERE\n",
    "    \n",
    "    #normalize probability\n",
    "    return classification, prob / total_ptobabilities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series_x = pd.Series([4.0, 2.3], index=['Flavanoids', 'Magnesium'])\n",
    "\n",
    "winning_class, prob = classify_naive_bayes(NB_classifer, series_x)\n",
    "winning_class, prob\n",
    "#SHOULD RETURN ('1', 0.50456450520692542)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations you have now fully implemented, trained and deployed your first classifier!**\n",
    "\n",
    "**Exercise:** Write a function that takes in at NB classifier and a dataset and classifies each sample in the dataset. It creates two new columns on the dataset called 'Classification' and 'Probability' of the classification and returns the data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_dataset(NB_classifer, df):\n",
    "    res = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        #YOUR CODE HERE\n",
    "\n",
    "    return pd.concat([df, res_df], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result = classify_dataset(NB_classifer, df)\n",
    "df_result.head(100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#SHOULD RETURN SOMETHING LIKE:\n",
    "   Class \tMagnesium \tFlavanoids \tClassification \tProbability\n",
    "0 \t1          2.80 \t3.06                1       0.908310\n",
    "1 \t1          2.65 \t2.76                1       0.780886\n",
    "2 \t1          2.80 \t3.24                1       0.923342\n",
    "3 \t1          3.85 \t3.49                1       0.865404\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Naive Bayes to k-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  Naive Bayes is a linear classifier, while k-NN is not. The\n",
    "curse of dimensionality and large feature sets are a problem for k-NN,\n",
    "while Naive Bayes performs well. k-NN requires no training (just load\n",
    "in the dataset), whereas Naive Bayes does. Both are examples of supervised\n",
    "learning (the data comes labeled). \n",
    "\n",
    "Schutt, R., & O'Neil, C. (2013). Doing Data Science: Straight Talk from the Frontline. \" O'Reilly Media, Inc.\".\n",
    "\n",
    "\n",
    "kNN is in many ways a special case of a supervised machine learning algorithm. It is unique in that the data itself is the model and no training of a classifier takes place explicitly. kNN is particularly susceptible to deteriorating accuracy if there are meaningless features in the dataset. Hence, feature analysis should always be performed together with dimensionality reduction if using kNN.\n",
    "\n",
    "Naive Bayes is more robust against outliers as well as un-informative features than kNN. However, one has to be careful with Naive Bayes because it is naive in terms of assuming independence between features, which is almost never true in reality. Therefore Naive Bayes is vulnerable when this assumption is strongly violated and when there is a large presence of highly correlated and redundant features, the training will bias the final result towards those features, and the final probabilities are unlikely to be accurate for interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of training a classifier, or creating a predictive model on a particular dataset is not so that it would make accurate predictions only on these samples. To use an absurd scenario, we could potentially create a look-up table, or an immense set of if-else statements for every example in a dataset and thereby achieve 100% accuracy. This process would be called memorising the data and is practically useless for the task of predictive analytics.\n",
    "\n",
    "Instead, the goal is that the classifier would uncover and encode patterns describing the underlying structural relationships, with the intention of them generalising and thus being able to accurately predict data that the algorithm has not previously \"seen\". This is referred to as  generalization. In essence, machine learning is the attempts to take the limited amount of information it can gather and generalise. it embodies the movement from the 'specific to the general'.\n",
    "\n",
    "Generalization is the property of a classifier or modelling process, whereby the classifier is relevant for prediction purposes on data that were not used to train it. We must keep in mind that every dataset is a finite sample of a total population for a given domain (unless you have a dataset that contains all samples that will ever be used to describe a given problem.). And we want the classifier to be fit-for-purpose on the population of a given domain as a whole.\n",
    "\n",
    "Hence, creating a classifier that is perfectly accurate on one a training dataset is no guarantee of it being accurate at predicting unseen samples. In fact, machine learning algorithms are notoriously susceptible to finding meaningless, or phantom patterns that are random idiosyncrasies within a given dataset sample, and have no value beyond the data outside of the training dataset. \n",
    "\n",
    "Sometimes we may have concerns that the training data were not representative of the true population which leads to bad generalization - and this does happen, often. The data can be noisy (mislabelled or erroneous data), have lots of outliers (valid but extreme values). But often it is the case that the algorithm used to train a classifier or build a model, created too good of a \"fit\" (too complex) on the training dataset that is ultimately useless and misleading beyond the samples it trained on.\n",
    "\n",
    "Training classifiers which are variable-size (optimisable) and can thus increase in complexity, often leads to the pattern below. Both the training and generalisation (test) error decrease initially during the early stages of classifier training. If the training ceases too early, then the classifier has usually not been given enough time to learn the separating class decision boundary sufficiently. This is referred to as underfitting. As the training algorithm builds a more complex classifier (model), the training error will continue to decrease. As the training error approaches zero, the training algorithm is said to 'converge'. However, complete convergence does not necessarily mean that the classifier will generalise well. It is usually quite easy to achieve full convergence on a training set. The difference between the final training error (convergence) and the generalisation (test) error is the indicator of the degree of overfitting that has occurred. Generalisation error will always be greater than the training error. However, we want this difference to be as small as possible.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Source Wikipedia](figures/generalization_overfitting.jpg)\n",
    "\n",
    "Source: Janert, P. K. (2010). Data analysis with open source tools.  O'Reilly Media, Inc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting is usually what happens when classifier generalization is not achieved. It is the tendency of machine learning and data mining algorithms to tailor classifiers to the training data, at the expense of generalization to previously unseen data points. \n",
    "\n",
    "It should be noted that inherent within all machine learning and data mining algorithms is the tendency to overfit to some degree. Some algorithms will accentuate this tendency more than others and it will often depend on the dataset and the type of the problem.\n",
    "\n",
    "If we try hard enough and push the classifiers to become more and more complex, the algorithms will invariably find patterns in a dataset. The Nobel Laureate Ronald Coase one said\n",
    "\n",
    "> “If you torture the data long enough, it will confess.”\n",
    "\n",
    "The problem of overfitting is probably one of the greatest challenges for a data scientist.\n",
    "\n",
    "> The answer is not to use a data mining procedure\n",
    "that doesn’t overfit because all of them do. Nor is the answer to simply use models\n",
    "that produce less overfitting, because there is a fundamental trade-off between model\n",
    "complexity and the possibility of overfitting. Sometimes we may simply want more\n",
    "complex models, because they will better capture the real complexities of the application\n",
    "and thereby be more accurate. There is no single choice or procedure that will eliminate\n",
    "overfitting. The best strategy is to recognize overfitting and to manage complexity in a\n",
    "principled way.\n",
    "\n",
    "Provost, F., & Fawcett, T. (2013). Data Science for Business: What you need to know about data mining and data-analytic thinking. \" O'Reilly Media, Inc.\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be able to ascertain if our classifier is both learning the training dataset (converging) or overfitting on previously unseen data, we need to have some evaluation metrics at our disposal. \n",
    "\n",
    "Fortunately the field of machine learning and data mining has been around for a long time so there are some very well established metric that enables us to evaluate our classifiers.\n",
    "\n",
    "Multiclass classification problems are treated similarly, however, there is usually a greater need in multiclass problems to break down the classification results at per-class label level in order to examine the performance. This is often necessary in the presence of unbalanced class distributions. \n",
    "\n",
    "A binary class confusion-matrix is a good starting point to visualize and understand the performance of a classifier. Each column of the matrix represents the instances in a predicted class, while each row represents the instances in an actual class. The name stems from the fact that it makes it easy to see if the system is confusing two classes (i.e. commonly mislabelling one as another)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Source Wikipedia](figures/confusion_matrix.jpg)\n",
    "\n",
    "Source: http://en.wikipedia.org/wiki/Confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Source Wikipedia](figures/classification_terms.jpg)\n",
    "\n",
    "Source: http://en.wikipedia.org/wiki/Confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-36c4af5e6595>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_result' is not defined"
     ]
    }
   ],
   "source": [
    "df_result.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_result.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_result['Classification'] = df_result['Classification'].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Given the Wine df_result from above, write a function that accepts it and returns a confusion matrix data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_confusion_matrix(df):\n",
    "    #YOUR CODE HERE\n",
    "            \n",
    "    return confusion_matrix_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print calculate_confusion_matrix(df_result)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#SHOULD RETURN\n",
    "    0   1   2\n",
    "0  43   0   4\n",
    "1   0  50   9\n",
    "2   9  17  45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = list(df.Class.unique())\n",
    "idx.sort()\n",
    "print idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a multiclass scenario, the confusion matrix can easily be extended it an $n \\times n$ matrix where $n$ is the number of classes. In a multiclass setting it is particularly informative to know which classes are being misclassified as labels of another class. \n",
    "\n",
    "Below is an example of a multiclass matrix from  a real-word dataset having 5 class labels:\n",
    "\n",
    "![Source Wikipedia](figures/multiclass_confusion_matrix.jpg)\n",
    "\n",
    "Another important measure that is insightful in respect to the accuracy of each given class label is the F-value (known also as the F-measure or the F-score), whose calculation can be made using the following:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"font-size: 150%;\"> \n",
    "$F_i = 2 \\times \\frac{\\mathrm{Precision_i} \\times \\mathrm{Recall_i}}{\\mathrm{Precision_i} + \\mathrm{Recall_i}}$\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The example below gives another real-world example (using the Yeast dataset from https://archive.ics.uci.edu/ml/datasets/Yeast) of how the F-values metric can be displayed. This example particularly demonstrates the problem of datasets that possess uneven class distributions. Training classifier on such problem is very difficult and all algorithms struggle to produce classifiers that accurately generalises on all class labels within such datasets. Evaluating datasets with such problems is to some degree elevated using the F-value metric:\n",
    "\n",
    "![Source Wikipedia](figures/f_value_example_on_yeast_dataset.jpg)\n",
    "\n",
    "Often though, on class-unbalanced problems, it is necessary to derive a single value to express the accuracy of a dataset. In these cases the total error (or accuracy) metrics as completely inadequate and a very good alternative is the Geometric mean:\n",
    "\n",
    "\n",
    "<div style=\"font-size: 120%;\">  \n",
    "$Geometric\\ mean = \\left(\\prod_{i=1}^n Recall_i \\right)^{1/n}$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Write a function that calculates the geometric mean for the data frame below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_geometric_mean(df):\n",
    "    gmean = 1.0\n",
    "    matrix = calculate_confusion_matrix(df)\n",
    "    \n",
    "    for i in range(len(matrix)):\n",
    "        #YOUR CODE HERE\n",
    "   \n",
    "    return np.power(gmean, 1.0 / float(len(matrix)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calculate_geometric_mean(df_result)\n",
    "#SHOULD PRODUCE 0.78912823939580679\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under generalization and overfitting, we discussed the importance of developing classifiers that do not just remember the training data but are able to generalize on data that the machine learning algorithms had not previously seen. One solution is to split datasets into training and test sets. The training is performed on one, and the generalization is determined on the other.\n",
    "\n",
    "There are some problems with doing it this way. By defining  two sets, we reduce the number of samples which can be used for learning the model, and the results can depend on a particular random choice for the pair of (train, test) sets. Also, what proportion of data do we use for training and what for testing?\n",
    "\n",
    "Another approach which is more robust, is to split the whole data several consecutive times in different\n",
    "train set and test set combinations, and to return the averaged value of the prediction\n",
    "scores obtained with the different sets. This technique is called **k-fold cross-validation**. Where the k determines the number segments that the data is to be split into. In this procedure, 1 fold is retained for testing the classifier and the other k-1 folds are used for training.\n",
    "\n",
    "In the image example below, k=4 (4 folds). The classifier will be trained on the combination of 3 folds and  evaluated on the 4th fold (the test fold). This procedure is then repeated 4 times until every fold has been used as the test set once so that we can eventually calculate the average error rate of our model from the error rate of every iteration, which gives us an idea of how well our model generalizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Source Wikipedia](figures/cross-validation-001_small.png)\n",
    "\n",
    "Source: https://github.com/rasbt/pattern_classification/blob/master/machine_learning/supervised_intro/images/cross-validation-001_small.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that the algorithm at all times is provided with the correct answers, but when the algorithm makes predictions, it does not refer to them, but instead uses the correct answers only to compare its own prediction to.\n",
    "\n",
    "Give the serious problem of class-imbalanced datasets, the most robust way to implement the above procedure is by using what is called the **stratified k-fold cross-validation**. By stratified, we mean that every fold will not only be of equal size as the other folds in terms of the number of samples, but every fold will also have an identical distribution of all class labels.\n",
    "\n",
    "Overall, the cross-validation approach can be computationally expensive but it is worth the extra effort and it does not waste too much data\n",
    "when creating the classifiers as it occurs  when fixing an arbitrary test set. This is an advantage in problems where the number of samples is very small. The question once you have trained and tested all your k classifiers is, which classifier to deploy in your application?\n",
    "\n",
    "Below is an example of a script that I have written to create a stratified k-fold cross-validation datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['1', '2.8', '3.06']\n",
      "1 ['1', '2.65', '2.76']\n",
      "1 ['1', '2.8', '3.24']\n",
      "1 ['1', '3.85', '3.49']\n",
      "1 ['1', '2.8', '2.69']\n",
      "1 ['1', '3.27', '3.39']\n",
      "1 ['1', '2.5', '2.52']\n",
      "1 ['1', '2.6', '2.51']\n",
      "1 ['1', '2.8', '2.98']\n",
      "1 ['1', '2.98', '3.15']\n",
      "1 ['1', '2.95', '3.32']\n",
      "1 ['1', '2.2', '2.43']\n",
      "1 ['1', '2.6', '2.76']\n",
      "1 ['1', '3.1', '3.69']\n",
      "1 ['1', '3.3', '3.64']\n",
      "1 ['1', '2.85', '2.91']\n",
      "1 ['1', '2.8', '3.14']\n",
      "1 ['1', '2.95', '3.4']\n",
      "1 ['1', '3.3', '3.93']\n",
      "1 ['1', '2.7', '3.03']\n",
      "1 ['1', '3.0', '3.17']\n",
      "1 ['1', '2.41', '2.41']\n",
      "1 ['1', '2.61', '2.88']\n",
      "1 ['1', '2.48', '2.37']\n",
      "1 ['1', '2.53', '2.61']\n",
      "1 ['1', '2.63', '2.68']\n",
      "1 ['1', '2.85', '2.94']\n",
      "1 ['1', '2.4', '2.19']\n",
      "1 ['1', '2.95', '2.97']\n",
      "1 ['1', '2.65', '2.33']\n",
      "1 ['1', '3.0', '3.25']\n",
      "1 ['1', '2.86', '3.19']\n",
      "1 ['1', '2.42', '2.69']\n",
      "1 ['1', '2.95', '2.74']\n",
      "1 ['1', '2.35', '2.53']\n",
      "1 ['1', '2.7', '2.98']\n",
      "1 ['1', '2.6', '2.68']\n",
      "1 ['1', '2.45', '2.43']\n",
      "1 ['1', '2.4', '2.64']\n",
      "1 ['1', '3.0', '3.04']\n",
      "1 ['1', '3.15', '3.29']\n",
      "1 ['1', '2.45', '2.68']\n",
      "1 ['1', '3.25', '3.56']\n",
      "1 ['1', '2.64', '2.63']\n",
      "1 ['1', '3.0', '3.0']\n",
      "1 ['1', '2.85', '2.65']\n",
      "1 ['1', '3.25', '3.17']\n",
      "1 ['1', '3.1', '3.39']\n",
      "1 ['1', '2.75', '2.92']\n",
      "1 ['1', '2.88', '3.54']\n",
      "1 ['1', '2.72', '3.27']\n",
      "1 ['1', '2.45', '2.99']\n",
      "1 ['1', '3.88', '3.74']\n",
      "1 ['1', '3.0', '2.79']\n",
      "1 ['1', '2.6', '2.9']\n",
      "1 ['1', '2.96', '2.78']\n",
      "1 ['1', '3.2', '3.0']\n",
      "1 ['1', '3.0', '3.23']\n",
      "1 ['1', '3.4', '3.67']\n",
      "2 ['2', '1.98', '0.57']\n",
      "2 ['2', '2.05', '1.09']\n",
      "2 ['2', '2.02', '1.41']\n",
      "2 ['2', '2.1', '1.79']\n",
      "2 ['2', '3.5', '3.1']\n",
      "2 ['2', '1.89', '1.75']\n",
      "2 ['2', '2.42', '2.65']\n",
      "2 ['2', '2.98', '3.18']\n",
      "2 ['2', '2.11', '2.0']\n",
      "2 ['2', '2.53', '1.3']\n",
      "2 ['2', '1.85', '1.28']\n",
      "2 ['2', '1.1', '1.02']\n",
      "2 ['2', '2.95', '2.86']\n",
      "2 ['2', '1.88', '1.84']\n",
      "2 ['2', '3.3', '2.89']\n",
      "2 ['2', '3.38', '2.14']\n",
      "2 ['2', '1.61', '1.57']\n",
      "2 ['2', '1.95', '2.03']\n",
      "2 ['2', '1.72', '1.32']\n",
      "2 ['2', '1.9', '1.85']\n",
      "2 ['2', '2.83', '2.55']\n",
      "2 ['2', '2.42', '2.26']\n",
      "2 ['2', '2.2', '2.53']\n",
      "2 ['2', '2.0', '1.58']\n",
      "2 ['2', '1.65', '1.59']\n",
      "2 ['2', '2.2', '2.21']\n",
      "2 ['2', '2.2', '1.94']\n",
      "2 ['2', '1.78', '1.69']\n",
      "2 ['2', '1.92', '1.61']\n",
      "2 ['2', '1.95', '1.69']\n",
      "2 ['2', '2.2', '1.59']\n",
      "2 ['2', '1.6', '1.5']\n",
      "2 ['2', '1.45', '1.25']\n",
      "2 ['2', '1.38', '1.46']\n",
      "2 ['2', '2.45', '2.25']\n",
      "2 ['2', '3.02', '2.26']\n",
      "2 ['2', '2.5', '2.27']\n",
      "2 ['2', '1.6', '0.99']\n",
      "2 ['2', '2.55', '2.5']\n",
      "2 ['2', '3.52', '3.75']\n",
      "2 ['2', '2.85', '2.99']\n",
      "2 ['2', '2.23', '2.17']\n",
      "2 ['2', '1.45', '1.36']\n",
      "2 ['2', '2.56', '2.11']\n",
      "2 ['2', '2.5', '1.64']\n",
      "2 ['2', '2.2', '1.92']\n",
      "2 ['2', '1.68', '1.84']\n",
      "2 ['2', '1.65', '2.03']\n",
      "2 ['2', '1.38', '1.76']\n",
      "2 ['2', '2.36', '2.04']\n",
      "2 ['2', '2.74', '2.92']\n",
      "2 ['2', '3.18', '2.58']\n",
      "2 ['2', '2.55', '2.27']\n",
      "2 ['2', '1.75', '2.03']\n",
      "2 ['2', '2.48', '2.01']\n",
      "2 ['2', '2.56', '2.29']\n",
      "2 ['2', '2.46', '2.17']\n",
      "2 ['2', '1.98', '1.6']\n",
      "2 ['2', '2.0', '2.09']\n",
      "2 ['2', '1.63', '1.25']\n",
      "2 ['2', '2.0', '1.64']\n",
      "2 ['2', '2.9', '2.79']\n",
      "2 ['2', '3.18', '5.08']\n",
      "2 ['2', '2.2', '2.13']\n",
      "2 ['2', '2.62', '2.65']\n",
      "2 ['2', '2.86', '3.03']\n",
      "2 ['2', '2.6', '2.65']\n",
      "2 ['2', '2.74', '3.15']\n",
      "2 ['2', '2.13', '2.24']\n",
      "2 ['2', '2.22', '2.45']\n",
      "2 ['2', '2.1', '1.75']\n",
      "0 ['0', '1.51', '1.25']\n",
      "0 ['0', '1.3', '1.22']\n",
      "0 ['0', '1.15', '1.09']\n",
      "0 ['0', '1.7', '1.2']\n",
      "0 ['0', '2.0', '0.58']\n",
      "0 ['0', '1.62', '0.66']\n",
      "0 ['0', '1.38', '0.47']\n",
      "0 ['0', '1.79', '0.6']\n",
      "0 ['0', '1.62', '0.48']\n",
      "0 ['0', '2.32', '0.6']\n",
      "0 ['0', '1.54', '0.5']\n",
      "0 ['0', '1.4', '0.5']\n",
      "0 ['0', '1.55', '0.52']\n",
      "0 ['0', '2.0', '0.8']\n",
      "0 ['0', '1.38', '0.78']\n",
      "0 ['0', '1.5', '0.55']\n",
      "0 ['0', '0.98', '0.34']\n",
      "0 ['0', '1.7', '0.65']\n",
      "0 ['0', '1.93', '0.76']\n",
      "0 ['0', '1.41', '1.39']\n",
      "0 ['0', '1.4', '1.57']\n",
      "0 ['0', '1.48', '1.36']\n",
      "0 ['0', '2.2', '1.28']\n",
      "0 ['0', '1.8', '0.83']\n",
      "0 ['0', '1.48', '0.58']\n",
      "0 ['0', '1.74', '0.63']\n",
      "0 ['0', '1.8', '0.83']\n",
      "0 ['0', '1.9', '0.58']\n",
      "0 ['0', '2.8', '1.31']\n",
      "0 ['0', '2.6', '1.1']\n",
      "0 ['0', '2.3', '0.92']\n",
      "0 ['0', '1.83', '0.56']\n",
      "0 ['0', '1.65', '0.6']\n",
      "0 ['0', '1.39', '0.7']\n",
      "0 ['0', '1.35', '0.68']\n",
      "0 ['0', '1.28', '0.47']\n",
      "0 ['0', '1.7', '0.92']\n",
      "0 ['0', '1.48', '0.66']\n",
      "0 ['0', '1.55', '0.84']\n",
      "0 ['0', '1.98', '0.96']\n",
      "0 ['0', '1.25', '0.49']\n",
      "0 ['0', '1.39', '0.51']\n",
      "0 ['0', '1.68', '0.7']\n",
      "0 ['0', '1.68', '0.61']\n",
      "0 ['0', '1.8', '0.75']\n",
      "0 ['0', '1.59', '0.69']\n",
      "0 ['0', '1.65', '0.68']\n",
      "0 ['0', '2.05', '0.76']\n",
      "opening 0\n",
      "opening 1\n",
      "opening 2\n",
      "opening 3\n",
      "opening 4\n"
     ]
    }
   ],
   "source": [
    "import random as rand\n",
    "\n",
    "kfolds = 5\n",
    "class_index = 0\n",
    "num_of_features = 13\n",
    "num_of_classes = 3\n",
    "\n",
    "file_name = ['fold_' + str(x) for x in range(kfolds)]\n",
    "\n",
    "# 1 load all samples into a list of lists\n",
    "feature_vectors_per_class = [[] * 1 for i in xrange(num_of_classes)]# [[]] * num_of_classes\n",
    "with open('wine_data_test.csv') as input_file:\n",
    "    for feature_vector_line in input_file:\n",
    "        feature_vector_line = feature_vector_line.rstrip()\n",
    "        elements = feature_vector_line.split(',')\n",
    "        class_type = int(elements[class_index])\n",
    "        if class_index > 0:\n",
    "            del elements[class_index]\n",
    "            elements.insert(0, str(class_type))\n",
    "        print class_type, elements\n",
    "        feature_vectors_per_class[class_type].append(elements)\n",
    "\n",
    "\n",
    "# 2 check len on lists and kfolds - figure out distributions\n",
    "num_of_samples = 0\n",
    "for i in range(num_of_classes):\n",
    "    samples = len(feature_vectors_per_class[i])\n",
    "    num_of_samples += samples\n",
    "    if len(feature_vectors_per_class[i]) < kfolds:\n",
    "        print('Cannot create stratified splits as number of kfolds greater than the size of samples in class {0}'.format(i))\n",
    "        exit()\n",
    "\n",
    "# 3 figure out the distribution per class per samples\n",
    "sample_from_each_class = []\n",
    "for i in range(num_of_classes):\n",
    "    samples = len(feature_vectors_per_class[i])\n",
    "    sample_from_each_class.append(samples / kfolds)\n",
    "\n",
    "\n",
    "# 4 for each fold randomly selct samples and delete from list\n",
    "fold = [[] * 1 for i in xrange(kfolds)]\n",
    "for k in range(kfolds):\n",
    "  for class_type in range(num_of_classes):\n",
    "    samples = sample_from_each_class[class_type]\n",
    "    if k  == kfolds - 1:\n",
    "          for s in range(len(feature_vectors_per_class[class_type])):\n",
    "                fold[k].append(feature_vectors_per_class[class_type][s])\n",
    "                value = feature_vectors_per_class[class_type][s]\n",
    "          continue\n",
    "    for s in range(samples):\n",
    "            if len(feature_vectors_per_class[class_type]) == 0:\n",
    "                break\n",
    "            idx = rand.randrange(0, len(feature_vectors_per_class[class_type]))\n",
    "            fold[k].append(feature_vectors_per_class[class_type][idx])\n",
    "            value = feature_vectors_per_class[class_type][idx]\n",
    "            feature_vectors_per_class[class_type].remove(value) \n",
    "\n",
    "# 5 save folds into file_content -  write into files the size and feature info\n",
    "#open each file and write sample size and features - followed by vectors\n",
    "output_files = []\n",
    "for i in range(0, int(kfolds)):\n",
    "    print \"opening \" + str(i)\n",
    "    output_files.append( open(file_name[i], 'w'))\n",
    "    output_files[i].write(str(len(fold[i])) + \" \" + str(num_of_features) + \"\\n\")\n",
    "    for sample in range(0, len(fold[i])):\n",
    "           output_files[i].write(' '.join(fold[i][sample]) + \"\\n\")\n",
    "           output_files[i].flush()\n",
    "    output_files[i].close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Evaluating Multiple Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working in the fields of machine learning inevitably requires the practitioner to **compare the generalizability of one (or more) algorithm against others** in order to determine which might be a better solution for a given problem.\n",
    "\n",
    "When performing such comparisons, it is important to realize that same algorithms, having different settings (such as the value for k in kNN) are seen as different algorithms and should be treated as such in the comparisons.\n",
    "\n",
    "The question is: how to best summarize a series of algorithms with different settings and their performances across multiple datasets? \n",
    "\n",
    "In such circumstances, the practitioner is referred to **statistical techniques** to provide answers. In particular, the practitioner is expected to provide summaries of every algorithm's accuracy in terms of **mean ranks** across all datasets. The mean ranks provides an informative summary of the **overall performance** of all algorithms that can then be analysed even further using **non-parametric** tests such as Friedman's test and a range of post hoc-tests. \n",
    "\n",
    "In essence, these tests evaluate if the difference in the mean ranks is statistically different enough from the expected mean. The rejection of the null-hypothesis then opens the door to detailing further which algorithm's mean ranks differ significantly from others'.\n",
    "\n",
    "Interested readers are referred to Demšar's article which provides examples on how to conduct statistical comparisons between multiple classifiers' results on multiple datasets:\n",
    "\n",
    "> Demšar, J. (2006). Statistical comparisons of classifiers over multiple data sets. The Journal of Machine Learning Research, 7, 1-30.\n",
    "\n",
    "The image below shows an example of how to display a summary of algorithms' performances using the geometric mean and the mean ranks: \n",
    "\n",
    "![Source Teo Susnjak](figures/ml_mean_rank_example.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Free Lunch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every model/classifier is a simplified representation of reality. By their very definition, simplifications discard irrelevant detail in order to enable a greater emphasis of some aspect of reality of interest for further study.  \n",
    "\n",
    "These simplifications are founded on assumptions that every machine learning algorithm embodies to varying degrees. These assumptions may hold in some situations, but not others. The consequence is, that a classifier that operates well in a certain situation well may fail in another. Making bold claims that a given machine learning algorithm is more accurate than another is therefore strongly frowned upon.\n",
    "\n",
    "In 1997, Wolpert and Macready described the “No Free Lunch” theorem which simply states that there is no one model/classifier that works best for every problem. The truth is that assumptions of a really effective and accurate classifier for one problem may not hold for different one. Because of this, it is common in machine learning to try multiple models and find one that works best for a particular problem.  This is especially true in supervised learning; validation or cross-validation is commonly used to assess the predictive accuracies of multiple models of varying complexity to find the best model.  \n",
    "\n",
    "Therefore, depending on the problem domain and requirements, it is important consider multiple factors before settling on a machine learning algorithm. One must assess the trade-offs between speed, accuracy, and complexity/interpretability of different machine learning algorithms and their classifiers, and select one that works best for that particular problem and a set of requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Process Summarized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We **begin with a data set** containing multiple samples, elements, records, or instances (all are the same terms used by different disciplines). \n",
    "\n",
    "2. Each instance is a **feature vector** consists of a number of features or attributes.  \n",
    "\n",
    "3. One of the features is special: it represents the instance's class - the **class label**. Each instance **belongs to exactly one class**.\n",
    "\n",
    "4. Classification problems are either **binary** or **multiclass**.\n",
    "\n",
    "5. A number of classification algorithms are limited to only binary classification. However, multiclass problems can be **decomposed into series of binary classification problems** ie. an instance belongs to the target class or to any other class.\n",
    "\n",
    "6. A classifier takes as input an instance (i.e., a feature vector) and **produces a class label**.\n",
    "\n",
    "7. Creating and using a classifier entails a three-step process of: **training, testing, and deployment** in an application.\n",
    "\n",
    "8. We first split the existing data set into a **training set** and a **test set**. \n",
    "\n",
    "9. In the training phase, we present each instance from the training set to the classification algorithm. \n",
    "\n",
    "10. Then compare the class label produced by the algorithm to the true class label of the record in question.\n",
    "\n",
    "11. If possible, then we adjust the algorithm's **“parameters”** to achieve the greatest possible **accuracy** or, equivalently, the lowest possible **error rate**. \n",
    "\n",
    "12. The results can be **summarized** in a so-called **confusion matrix** whose entries are the number of records in each category.\n",
    "\n",
    "13. Unfortunately, the **error rate derived from the training set** (the training error) is typically **too optimistic** as an indicator of the error rate the classifier would achieve on new data — that is, on data that was not used during the learning phase. \n",
    "\n",
    "13. This is the purpose of the test set: after we have optimized the algorithm using only the training data, we let the classifier operate on the elements of the test set to see how well it classifies them. The error rate obtained in this way is the **generalization error** and is a much more reliable indicator of the accuracy of the classifier.\n",
    "\n",
    "14. Keep in mind the **trade-off** between **classifier complexity** and **overfitting**. The classifier can usually be tweaked to become more complex and  correctly learn all the training samples. But this is called overfitting and memorizing the data. On the other hand, if it is too simple, then it cannot learn the relationships within the data and both its training and generalization error will be poor; this is known as underfitting.\n",
    "\n",
    "15. Once a classifier has been developed and tested, it can be used to **classify truly new and unknown data points** — that is, data points for which the correct class label is not known. (This is in contrast to the test set, where the class labels were known but not used by the classifier when making a prediction.) \n",
    "\n",
    "Adapted from: \n",
    "> Source: Janert, P. K. (2010). Data analysis with open source tools.  O'Reilly Media, Inc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Flavanoids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Magnesium  Flavanoids\n",
       "0      1       2.80        3.06\n",
       "1      1       2.65        2.76\n",
       "2      1       2.80        3.24\n",
       "3      1       3.85        3.49\n",
       "4      1       2.80        2.69"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can train a Naive Bayes classifier on all our training data as follows and use the model for prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = nb.fit(df[['Magnesium','Flavanoids']], df['Class'])\n",
    "classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find out how well our classifier learned the training dataset based on overall accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7808988764044944"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(df[['Magnesium','Flavanoids']], df['Class'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can use the classifier to classifier individual samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "print 'Predicted class: ', classifier.predict([2.2, 3.3])[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to split the dataset into a training and test set with the test set comprising 20% is the dataset, we do as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 2)\n",
      "(36, 2)\n",
      "(142L,)\n",
      "(36L,)\n"
     ]
    }
   ],
   "source": [
    "# split into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['Magnesium','Flavanoids']], df['Class'], random_state=1, test_size=0.2)\n",
    "print X_train.shape\n",
    "print X_test.shape\n",
    "\n",
    "print y_train.shape\n",
    "print y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train the classifier on the training dataset and test it on the unseen dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 2, 1, 0, 2, 1, 0, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 2, 1, 0, 1, 2, 2, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = nb.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72222222222222221"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate a more comprehensive accuracy report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80         9\n",
      "          1       0.71      0.86      0.77        14\n",
      "          2       0.62      0.62      0.62        13\n",
      "\n",
      "avg / total       0.75      0.72      0.72        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print metrics.classification_report(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the confusion matrix looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  0  3]\n",
      " [ 0 12  2]\n",
      " [ 0  5  8]]\n"
     ]
    }
   ],
   "source": [
    "print metrics.confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we would prefer to use stratified cross-fold validations, then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.875     ,  0.875     ,  0.875     ,  0.57142857,  0.6       ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "classifierNB = GaussianNB()\n",
    "scores = cross_val_score(classifierNB, X_test, y_test, cv=5, scoring='accuracy')\n",
    "scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above uses 5 folds and uses accuracy for a general evaluation metric. The returned result is accuracy for each of the folds.\n",
    "\n",
    "We can find the mean and standard deviation of all the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean is:  0.759285714286\n",
      "STD is:  0.142008191773\n"
     ]
    }
   ],
   "source": [
    "print 'mean is: ', scores.mean()\n",
    "print 'STD is: ', scores.std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Load the student grade dataset and use the Naive Bayes classifier to predict the class grade based on all the assignment results.\n",
    "\n",
    "First train all the data and test the accuracy.\n",
    "\n",
    "Then use different number of folds to test the accuracy of the generalization of your classifiers.\n",
    "\n",
    "Lastly, experiment with using different combinations of assignment features and observe if the accuracy increases/decreases as you omit some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "require(['base/js/utils'],\n",
    "function(utils) {\n",
    "   utils.load_extensions('calico-spell-check', 'calico-document-tools', 'calico-cell-tools');\n",
    "});\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
